---
title: "Practical Machine Learning Course Project"
author: "Craig Covey"
date: "May 16, 2016"
output: html_document
---

<style type="text/css">
  h1 {
   color: #1F3A93
  }
  h2 { 
   color: #3399ff;		
  }
  h3 { 
   color: #446CB3;		
  }
  body, td {
     font-size: 14px;
  }
  code.r{
    font-size: 14px;
  }
  pre {
    font-size: 12px
  }
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE)
```

#Overview
One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, I will use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict the manner in which they did the exercise. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

#Executive Summary
I use decision trees and random forest machine learning algorithms to predict the type of exercise. After downloading the training and testing sets from the internet and performing some simple exploratory data analysis I see there are many columns that are mostly either blank or NAs. I split the provided training data set into a training `myTraining` and testing `myTesting` data set. I will use these data sets to perform my machine learning algorithms. Next I remove all columns from `myTraining` and `myTesting` data sets that are predominately NAs. This will improve my models. After cleaning up the data I first performed decision trees machine learning. 
My most successfull decision tree model produce an 86% accuracy got _____ right

Next I used random forests machine learning that produced an ____ % accuracy and got ____ right
```{r}

```

***

#Data Processing

add commentary .....
```{r, eval=TRUE}
## Load Library Packages
library(ggplot2)
library(dplyr)
library(caret)
library(rattle)
library(rpart)
library(rpart.plot)
library(e1071)
library(randomForest)
library(gbm)
library(RCurl)
library(MASS)
library(knitr)

## Download the data
trainingURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testingURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

trainingPath <- "pml-training.csv"
testingPath <- "pml-testing.csv"

## Download the training data
if (url.exists(trainingURL)) {
    if (!file.exists(trainingPath)) {
        download.file(trainingURL, method = "libcurl", destfile = trainingPath)
    }
}

## Download the testing data
if (url.exists(testingURL)) {
    if (!file.exists(testingPath)) {
        download.file(testingURL, method = "libcurl", destfile = testingPath)
    }
}

## Load the data into R
training <- read.csv(trainingPath, header = TRUE, sep = ",", na.strings = c("", "NA"), fill = TRUE,
                     stringsAsFactors = TRUE)
testing <- read.csv(testingPath, header = TRUE, sep = ",", na.strings = c("", "NA"), fill = TRUE,
                    stringsAsFactors = TRUE)
```

***

#Exploratory Data Analysis

Use glimpse() function from the dplyr package to inspect data. I did not include output for report brevity.
```{r, eval=FALSE}
glimpse(training)
```
```{r}
## Find number of subjects and classes
table(training[, c("user_name", "classe")])
```
> Analysis:  
>

***

#Data Transformation

add commentary ....

```{r}
### Partioning the training set
indexTrain <- createDataPartition(y = training$classe, p = 0.7, list = FALSE)
myTraining <- training[indexTrain, ]
myTesting <- training[-indexTrain, ]

### Training Data Set

## Remove the first column. It is not needed it is just the row number
myTraining <- myTraining[ ,-1]

## Count the number of NAs in each column of the training set
countTrainNAs <- c()
for(i in 1:dim(myTraining)[2]) {
    countTrainNAs <- append(countTrainNAs, sum( is.na( myTraining[ ,i])))
}

## Remove columns from training set that have NAs
for(j in dim(myTraining)[2]:1) {
    if (countTrainNAs[j] > 1) {
        myTraining <- myTraining[ , -j]
    }
}

## Now, do the exact same thing to the myTesting data set
myTesting <- myTesting[, -1]

countTestNAs <- c()
for(i in 1:dim(myTesting)[2]) {
    countTestNAs <- append(countTestNAs, sum( is.na( myTesting[ ,i])))
}

## Remove columns from testing set that have NAs
for(j in dim(myTesting)[2]:1) {
    if (countTestNAs[j] > 1) {
        myTesting <- myTesting[ , -j]
    }
}

## Repeat the same process for the testing set

# Remove first column which is a row number column
testing <- testing[, -1]

countTestNAs <- c()
for(i in 1:dim(testing)[2]) {
    countTestNAs <- append(countTestNAs, sum( is.na( testing[ ,i])))
}

## Remove columns from testing set that have NAs
for(j in dim(testing)[2]:1) {
    if (countTestNAs[j] == 20) {
        testing <- testing[ , -j]
    }
}

dim(myTraining)
dim(myTesting)
dim(testing)
```

add commentary ...

```{r}
common <- intersect(names(myTraining), names(testing))
for (p in common) {
    if (class(myTraining[[p]]) == "factor") {
        levels(testing[[p]]) <- levels(myTraining[[p]])
    }
}
```
> Analysis:  
>

***

#Machine Learning Algorithm: Decision Trees

###Using the `train()` function
```{r}
treesModel <- train(classe ~ ., data = myTraining, method = "rpart")
# print fancy decision tree
rattle::fancyRpartPlot(treesModel$finalModel)
## Prediction
pred.trees.train <- predict(treesModel, myTesting)
## Confusion matrix
options(scipen = 999) # disables printing scientific notation
# Out of sample error
confusionMatrix(pred.trees.train, myTesting$classe)$table
# Accuracy
round(confusionMatrix(pred.trees.train, myTesting$classe)$overall, digits = 5)
```
> Analysis:  
> Ouch 60% accuracy!

###Using the `rpart()` function
```{r}
rpartModel <- rpart(classe ~ ., data = myTraining, method = "class")
# print fancy decision tree
fancyRpartPlot(rpartModel)
## Prediction
pred.trees.rpart <- predict(rpartModel, myTesting, type = "class")
## Confusion Matrix
# Out of sample error
confusionMatrix(pred.trees.rpart, myTesting$classe)$table
# Accuracy
confusionMatrix(pred.trees.rpart, myTesting$classe)$overall
```
> Analysis:  
> A much better accuracy of 86%. Apparently, the `rpart()` function is vastly superior to the `train()` function as it relates to decision trees machine learning algorithms. But lets see if we can do better with random forest.

#Machine Learning Algorithm: Random Forests

###Using the `train()` function
```{r}
rf.model <- train(classe ~ ., data = myTraining, method = "rf",
                  trControl = trainControl(method = "cv", number = 10))
## Prediction
pred.rf.train <- predict(rf.model, myTesting)
## Confusion matrix
# Out of sample error
confusionMatrix(pred.rf.train, myTesting$classe)$table
# Accuracy
confusionMatrix(pred.rf.train, myTesting$classe)$overall
```
> Analysis:  
> 

###Using the `randomForest()` function
```{r}
modelRandFor <- randomForest(classe ~ ., data = myTraining)
## Prediction
pred.rf.randFor <- predict(modelRandFor, myTesting)
## Confustion Matrix
# Out of sample error
confusionMatrix(pred.rf.randFor, myTesting$classe)$table
# Accuracy
confusionMatrix(pred.rf.randFor, myTesting$classe)$overall
```
> Analysis:  
> 

